{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "import math\n",
    "import pickle\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import optuna\n",
    "import catboost as cb\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Boosting:\n",
    "\n",
    "    def __init__(self, X_train, X_val, y_train, y_val, cat_features, params = None):\n",
    "        print(\"Init...\")\n",
    "        self.X_train = X_train\n",
    "        self.X_val = X_val\n",
    "        self.y_train = y_train\n",
    "        self.y_val = y_val\n",
    "        self.cat_features = cat_features\n",
    "        self.params = params\n",
    "        self.model = None\n",
    "        self.best_params = None\n",
    "        self.top_features = None\n",
    "        self.train_pool = cb.Pool(data = X_train, label = y_train, cat_features = cat_features)\n",
    "        self.val_pool = cb.Pool(data = X_val, label = y_val, cat_features = cat_features)\n",
    "        print(\"Init Finished!\")\n",
    "\n",
    "    def train(self):\n",
    "        if self.params is None:\n",
    "            model = cb.CatBoostClassifier(\n",
    "                # learning_rate = 0.303,\n",
    "                # depth = 6,\n",
    "                # l2_leaf_reg = 2.437,\n",
    "                # random_seed = 42,\n",
    "                # min_data_in_leaf = 30,\n",
    "                # one_hot_max_size = 40,\n",
    "                # colsample_bylevel = 0.079,\n",
    "                loss_function = 'MultiClass',\n",
    "                task_type = 'CPU',\n",
    "                iterations = 200,\n",
    "                use_best_model = True,\n",
    "                verbose = 100,\n",
    "                thread_count = -1,\n",
    "                early_stopping_rounds = 100,\n",
    "                eval_metric = 'MultiClass',\n",
    "                # class_weights=weits,\n",
    "                # boosting_type = 'Plain',\n",
    "                # bootstrap_type = 'MVS'\n",
    "            )\n",
    "        else:\n",
    "            self.params[\"verbose\"] = 100\n",
    "            self.params[\"iterations\"] = 1000\n",
    "            model = cb.CatBoostClassifier(**self.params)\n",
    "\n",
    "        model.fit(\n",
    "            self.train_pool,\n",
    "            eval_set = self.val_pool\n",
    "        )\n",
    "        self.model = model\n",
    "        # y_train_pred = model.predict_proba(self.X_train)[:, 1]\n",
    "        # y_val_pred = model.predict_proba(self.X_val)[:, 1]\n",
    "\n",
    "        # roc_auc_tr = roc_auc_score(self.y_train, y_train_pred)\n",
    "        # roc_auc_val = roc_auc_score(self.y_val, y_val_pred)\n",
    "\n",
    "        # print(\"ROC AUC на обучающей выборке:\", roc_auc_tr)\n",
    "        # print(\"ROC AUC на валидационной выборке:\", roc_auc_val)\n",
    "\n",
    "\n",
    "    def optimize_hyperparams(self):\n",
    "\n",
    "        def objective(trial):\n",
    "            params = {\n",
    "                \"objective\" : trial.suggest_categorical(\"objective\", [\"MultiClass\"]),\n",
    "                \"learning_rate\" : trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e0),\n",
    "                \"l2_leaf_reg\" : trial.suggest_loguniform(\"l2_leaf_reg\", 1e-2, 3e0),\n",
    "                \"colsample_bylevel\" : trial.suggest_float(\"colsample_bylevel\", 0.01, 0.1, log = True),\n",
    "                \"depth\" : trial.suggest_int(\"depth\", 2, 5),\n",
    "                \"boosting_type\" : trial.suggest_categorical(\"boosting_type\", [\"Ordered\", \"Plain\"]),\n",
    "                \"bootstrap_type\" : trial.suggest_categorical(\"bootstrap_type\", [\"Bayesian\", \"Bernoulli\", \"MVS\"]),\n",
    "                \"min_data_in_leaf\" : trial.suggest_int(\"min_data_in_leaf\", 2, 50),\n",
    "                \"one_hot_max_size\" : trial.suggest_int(\"one_hot_max_size\", 2, 50),\n",
    "                \"iterations\" : trial.suggest_int(\"iterations\", 500, 3500),\n",
    "                \"eval_metric\" : \"AUC\"\n",
    "            }\n",
    "\n",
    "            if params[\"bootstrap_type\"] == \"Bayesian\":\n",
    "                params[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0, 10)\n",
    "            elif params[\"bootstrap_type\"] == \"Bernoulli\":\n",
    "                params[\"subsample\"] = trial.suggest_float(\"subsample\", 0.1, 1, log = True)\n",
    "\n",
    "            model = cb.CatBoostClassifier(\n",
    "                loss_function = 'Logloss',\n",
    "                random_seed = 42,\n",
    "                task_type = 'CPU',\n",
    "                use_best_model = True,\n",
    "                verbose = False,\n",
    "                **params\n",
    "            )\n",
    "\n",
    "            model.fit(\n",
    "                self.train_pool,\n",
    "                eval_set = self.val_pool\n",
    "            )\n",
    "\n",
    "            y_pred = model.predict_proba(self.X_val)[:, 1]\n",
    "\n",
    "            roc_auc = roc_auc_score(self.y_val, y_pred)\n",
    "\n",
    "            return roc_auc\n",
    "\n",
    "        study = optuna.create_study(pruner=optuna.pruners.MedianPruner(n_warmup_steps = 5), direction = \"maximize\")\n",
    "        study.optimize(objective, n_trials = 10, timeout = 60)\n",
    "\n",
    "        self.best_params = study.best_params\n",
    "\n",
    "        print(\"Best params:\", self.best_params)\n",
    "\n",
    "    def load_model(self, file_path):\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            self.model = pickle.load(f)\n",
    "\n",
    "    def save_model(self, file_path):\n",
    "        with open(file_path, \"wb\") as f:\n",
    "            pickle.dump(self.model, f)\n",
    "\n",
    "    def show_feats_imp(self):\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model not found!\")\n",
    "\n",
    "        feature_importance = self.model.feature_importances_\n",
    "        sorted_idx = np.argsort(feature_importance)\n",
    "\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.barh(range(len(sorted_idx)), feature_importance[sorted_idx], align='center')\n",
    "        plt.yticks(range(len(sorted_idx)), np.array(self.model.feature_names_)[sorted_idx])\n",
    "        plt.title(\"Feature Importance\")\n",
    "        plt.show()\n",
    "\n",
    "        self.top_features = np.flip(np.array(self.model.feature_names_)[sorted_idx])\n",
    "        print(self.top_features)\n",
    "\n",
    "    def top_feats_selection(self):\n",
    "\n",
    "        top = []\n",
    "        roc_tr = []\n",
    "        roc_val = []\n",
    "\n",
    "        for col in tqdm(self.top_features):\n",
    "\n",
    "            top.append(col)\n",
    "            top_cat = list(set(self.cat_features) & set(top))\n",
    "\n",
    "            train_pool = cb.Pool(data = self.X_train[top], label = self.y_train, cat_features = top_cat)\n",
    "            val_pool = cb.Pool(data = self.X_val[top], label = self.y_val, cat_features = top_cat)\n",
    "\n",
    "            if self.params is None:\n",
    "                model = cb.CatBoostClassifier(\n",
    "                    learning_rate = 0.303,\n",
    "                    depth = 6,\n",
    "                    l2_leaf_reg = 2.437,\n",
    "                    random_seed = 42,\n",
    "                    min_data_in_leaf = 30,\n",
    "                    one_hot_max_size = 40,\n",
    "                    colsample_bylevel = 0.079,\n",
    "                    loss_function = 'MultiClass',\n",
    "                    task_type = 'CPU',\n",
    "                    iterations = 1000,\n",
    "                    use_best_model = True,\n",
    "                    verbose = 100,\n",
    "                    thread_count = -1,\n",
    "                    early_stopping_rounds = 100,\n",
    "                    eval_metric = 'AUC',\n",
    "                    class_weights=weits,\n",
    "                    boosting_type = 'Plain',\n",
    "                    bootstrap_type = 'MVS'\n",
    "                )\n",
    "                path = \"no_optuna_top_features.xlsx\"\n",
    "            else:\n",
    "                self.params[\"verbose\"] = 0\n",
    "                self.params[\"iterations\"] = 500\n",
    "                path = \"optuna_top_features.xlsx\"\n",
    "                model = cb.CatBoostClassifier(**self.params)\n",
    "\n",
    "            model.fit(\n",
    "                train_pool,\n",
    "                eval_set = val_pool\n",
    "            )\n",
    "\n",
    "            y_train_pred = model.predict_proba(self.X_train[top])[:, 1]\n",
    "            y_val_pred = model.predict_proba(self.X_val[top])[:, 1]\n",
    "\n",
    "            roc_auc_tr = roc_auc_score(self.y_train, y_train_pred)\n",
    "            roc_auc_val = roc_auc_score(self.y_val, y_val_pred)\n",
    "\n",
    "            roc_tr.append(roc_auc_tr)\n",
    "            roc_val.append(roc_auc_val)\n",
    "\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.plot(range(len(self.top_features)), roc_tr, marker = 'o', label = 'Train')\n",
    "        plt.plot(range(len(self.top_features)), roc_val, marker = 'o', label = 'Valid')\n",
    "        plt.xlabel(\"Number of Top Features\")\n",
    "        plt.ylabel(\"ROC AUC\")\n",
    "        plt.title(\"ROC AUC on Top-K Features\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        stats = pd.DataFrame({\n",
    "            \"TRAIN\" : roc_tr,\n",
    "            \"VALID\" : roc_val\n",
    "        })\n",
    "\n",
    "        stats.to_excel(path, index = False)\n",
    "\n",
    "    def one_factor_roc(self):\n",
    "        story = pd.DataFrame()\n",
    "\n",
    "        for feature in tqdm(self.X_train.columns):\n",
    "            if self.params is None:\n",
    "                model = cb.CatBoostClassifier(\n",
    "                    learning_rate = 0.303,\n",
    "                    depth = 6,\n",
    "                    l2_leaf_reg = 2.437,\n",
    "                    random_seed = 42,\n",
    "                    min_data_in_leaf = 30,\n",
    "                    one_hot_max_size = 40,\n",
    "                    colsample_bylevel = 0.079,\n",
    "                    loss_function = 'MultiClass',\n",
    "                    task_type = 'CPU',\n",
    "                    iterations = 1000,\n",
    "                    use_best_model = True,\n",
    "                    verbose = 100,\n",
    "                    thread_count = -1,\n",
    "                    early_stopping_rounds = 100,\n",
    "                    eval_metric = 'AUC',\n",
    "                    class_weights=weits,\n",
    "                    boosting_type = 'Plain',\n",
    "                    bootstrap_type = 'MVS'\n",
    "                )\n",
    "                path = \"no_optuna_one_factor_roc.xlsx\"\n",
    "            else:\n",
    "                self.params[\"verbose\"] = False\n",
    "                self.params[\"iterations\"] = 500\n",
    "                path = \"optuna_one_factor_roc.xlsx\"\n",
    "                model = cb.CatBoostClassifier(**self.params)\n",
    "\n",
    "            if feature in self.cat_features:\n",
    "                train_pool = cb.Pool(data = self.X_train[[feature]], label = self.y_train, cat_features = [feature])\n",
    "                val_pool = cb.Pool(data = self.X_val[[feature]], label = self.y_val, cat_features = [feature])\n",
    "            else:\n",
    "                train_pool = cb.Pool(data = self.X_train[[feature]], label = self.y_train)\n",
    "                val_pool = cb.Pool(data = self.X_val[[feature]], label = self.y_val)\n",
    "\n",
    "            model.fit(\n",
    "                train_pool,\n",
    "                eval_set = val_pool\n",
    "            )\n",
    "\n",
    "            y_train_pred = model.predict_proba(self.X_train[[feature]])[:, 1]\n",
    "            y_val_pred = model.predict_proba(self.X_val[[feature]])[:, 1]\n",
    "\n",
    "            roc_auc_tr = roc_auc_score(self.y_train, y_train_pred)\n",
    "            roc_auc_val = roc_auc_score(self.y_val, y_val_pred)\n",
    "\n",
    "            story = story.append(pd.DataFrame({\n",
    "                'features' : [feature],\n",
    "                'train' : [roc_auc_tr],\n",
    "                'valid' : [roc_auc_val]\n",
    "            }), ignore_index = True)\n",
    "\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        plt.bar(range(len(story['features'])), story['train'], align = 'center', label = 'Train')\n",
    "        plt.bar(range(len(story['features'])), story['valid'], align = 'edge', label = 'Valid')\n",
    "        plt.xlabel(\"Features\")\n",
    "        plt.ylabel(\"ROC-AUC\")\n",
    "        plt.title(\"One-Factor ROC-AUC\")\n",
    "        plt.xticks(range(len(story['features'])), story['features'], rotation = 45)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        story.to_excel(path, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(\"train_data.pqt\")\n",
    "test_df = pd.read_parquet(\"test_data.pqt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_next = test_df.shift(-1)\n",
    "df_next = df_next.add_prefix('next_')\n",
    "result_test = pd.concat([test_df, df_next], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(['end_cluster'], axis = 1)\n",
    "\n",
    "df_next = train_df.shift(-1)\n",
    "df_next = df_next.add_prefix('next_')\n",
    "result_train = pd.concat([train_df, df_next], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_train = result_train[~(result_train['date'] == 'month_3')]\n",
    "result_train = pd.concat([result_train, result_test[result_test['date'] == 'month_4']], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test = result_test[result_test['date'] == 'month_5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test = result_test.drop(['next_start_cluster'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = result_train.corr().abs()\n",
    "\n",
    "# Получение верхнего треугольника матрицы корреляции (без диагонали)\n",
    "upper_triangle = corr_matrix.where(\n",
    "    np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Нахождение колонок, где корреляция больше 0.9\n",
    "to_drop = [column for column in upper_triangle.columns if any(upper_triangle[column] > 0.95)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_train = result_train.drop(to_drop, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test = result_test.drop(to_drop, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clever_one_hot(df, col): #переписать в lable encoding?\n",
    "    top_4 = df[col].value_counts().index[:4]\n",
    "    df.loc[~df[col].isin(top_4), col] = 'other'\n",
    "    one_hot_encoded = pd.get_dummies(df[col], prefix=col)\n",
    "    df = df.drop(col, axis=1)\n",
    "    return pd.concat([df, one_hot_encoded], axis=1)\n",
    "\n",
    "def feature_prossesing(df):\n",
    "    one_hot_encoded = pd.get_dummies(df['segment'], prefix='seg')\n",
    "    df = df.drop('segment', axis=1)\n",
    "    df = pd.concat([df, one_hot_encoded], axis=1)\n",
    "\n",
    "    df['ogrn_year'] = df['ogrn_year'].fillna('_-1')\n",
    "    df['ogrn_month'] = df['ogrn_month'].fillna('_-1')\n",
    "    df['ogrn_year'] = df['ogrn_year'].apply(lambda x: int(x.split('_')[-1]))\n",
    "    df['ogrn_month'] = df['ogrn_month'].apply(lambda x: int(x.split('_')[-1]))\n",
    "    df['lasting'] = df['ogrn_year']*12 + df['ogrn_month']\n",
    "    df['lasting'] = df['lasting'].apply(lambda x: x if x>=0 else -1)\n",
    "\n",
    "    del df['ogrn_year']\n",
    "    del df['ogrn_month']\n",
    "\n",
    "    for i in ['channel_code', 'city_type']:\n",
    "        df = clever_one_hot(df, i)\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    df['start_cluster'] = label_encoder.fit_transform(df['start_cluster'])\n",
    "    df['next_start_cluster'] = label_encoder.transform(df['next_start_cluster'])\n",
    "    category_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "\n",
    "    df = df.drop(df.select_dtypes(include=['object']).columns, axis=1)\n",
    "    df = df.fillna(-1)\n",
    "\n",
    "    return df, category_mapping   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, category_mapping = feature_prossesing(result_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'{other}': 0,\n",
       " '{}': 1,\n",
       " '{α, β}': 2,\n",
       " '{α, γ}': 3,\n",
       " '{α, δ}': 4,\n",
       " '{α, ε, η}': 5,\n",
       " '{α, ε, θ}': 6,\n",
       " '{α, ε, ψ}': 7,\n",
       " '{α, ε}': 8,\n",
       " '{α, η}': 9,\n",
       " '{α, θ}': 10,\n",
       " '{α, λ}': 11,\n",
       " '{α, μ}': 12,\n",
       " '{α, π}': 13,\n",
       " '{α, ψ}': 14,\n",
       " '{α}': 15,\n",
       " '{λ}': 16}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clever_one_hot(df, col, df1): #переписать в lable encoding?\n",
    "    top_4 = df1[col].value_counts().index[:4]\n",
    "    df.loc[~df[col].isin(top_4), col] = 'other'\n",
    "    one_hot_encoded = pd.get_dummies(df[col], prefix=col)\n",
    "    df = df.drop(col, axis=1)\n",
    "    return pd.concat([df, one_hot_encoded], axis=1)\n",
    "\n",
    "def feature_prossesing(df, df_1):\n",
    "    one_hot_encoded = pd.get_dummies(df['segment'], prefix='seg')\n",
    "    df = df.drop('segment', axis=1)\n",
    "    df = pd.concat([df, one_hot_encoded], axis=1)\n",
    "\n",
    "    df['ogrn_year'] = df['ogrn_year'].fillna('_-1')\n",
    "    df['ogrn_month'] = df['ogrn_month'].fillna('_-1')\n",
    "    df['ogrn_year'] = df['ogrn_year'].apply(lambda x: int(x.split('_')[-1]))\n",
    "    df['ogrn_month'] = df['ogrn_month'].apply(lambda x: int(x.split('_')[-1]))\n",
    "    df['lasting'] = df['ogrn_year']*12 + df['ogrn_month']\n",
    "    df['lasting'] = df['lasting'].apply(lambda x: x if x>=0 else -1)\n",
    "\n",
    "    del df['ogrn_year']\n",
    "    del df['ogrn_month']\n",
    "\n",
    "    for i in ['channel_code', 'city_type']:\n",
    "        df = clever_one_hot(df, i, df_1)\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    df['start_cluster'] = label_encoder.fit_transform(df['start_cluster'])\n",
    "    category_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "\n",
    "    df = df.drop(df.select_dtypes(include=['object']).columns, axis=1)\n",
    "    df = df.fillna(-1)\n",
    "\n",
    "    return df, category_mapping   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test, category_mapping = feature_prossesing(result_test, result_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['next_start_cluster']\n",
    "X = df.drop(['next_start_cluster'], axis=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init...\n",
      "Init Finished!\n"
     ]
    }
   ],
   "source": [
    "boosting = Boosting(X_train, X_val, y_train, y_val, cat_features = [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.225541\n",
      "0:\tlearn: 0.7503855\ttest: 0.7530491\tbest: 0.7530491 (0)\ttotal: 4.47s\tremaining: 14m 49s\n",
      "100:\tlearn: 0.2232716\ttest: 0.2309328\tbest: 0.2309328 (100)\ttotal: 8m 27s\tremaining: 8m 17s\n",
      "199:\tlearn: 0.2147725\ttest: 0.2258115\tbest: 0.2258115 (199)\ttotal: 18m 28s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2258115262\n",
      "bestIteration = 199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "boosting.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosting.save_model('model_month_norm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = list(boosting.model.predict(test).reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_mapping = {\n",
    "    0: '{other}',\n",
    "    1: '{}',\n",
    "    2: '{α, β}',\n",
    "    3: '{α, γ}',\n",
    "    4: '{α, δ}',\n",
    "    5: '{α, ε, η}',\n",
    "    6: '{α, ε, θ}',\n",
    "    7: '{α, ε, ψ}',\n",
    "    8: '{α, ε}',\n",
    "    9: '{α, η}',\n",
    "    10: '{α, θ}',\n",
    "    11: '{α, λ}',\n",
    "    12: '{α, μ}',\n",
    "    13: '{α, π}',\n",
    "    14: '{α, ψ}',\n",
    "    15: '{α}',\n",
    "    16: '{λ}'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = [column_mapping[i] for i in ans]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_parquet(\"test_data.pqt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.loc[test_df['date'] == 'month_6', 'start_cluster'] = ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.831\n"
     ]
    }
   ],
   "source": [
    "a = list(test_df[test_df['date'] == 'month_5']['start_cluster'])\n",
    "b = list(test_df[test_df['date'] == 'month_6']['start_cluster'])\n",
    "\n",
    "cnt =0\n",
    "\n",
    "for i in range(len(a)):\n",
    "    if a[i] != b[i]:\n",
    "        cnt+=1\n",
    "\n",
    "print(cnt/len(a) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_parquet('test_df.pqt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
