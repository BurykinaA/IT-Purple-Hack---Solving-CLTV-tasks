{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8b7bef09-9e86-4b19-bbb7-e0ccb7515328",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-14T22:50:38.627643Z",
          "iopub.status.busy": "2024-02-14T22:50:38.627255Z",
          "iopub.status.idle": "2024-02-14T22:50:39.496067Z",
          "shell.execute_reply": "2024-02-14T22:50:39.495215Z",
          "shell.execute_reply.started": "2024-02-14T22:50:38.627616Z"
        },
        "id": "8b7bef09-9e86-4b19-bbb7-e0ccb7515328",
        "tags": []
      },
      "source": [
        "# Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e0ddb399-18f4-4051-86c0-39f1c623eef5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-15T11:34:39.109032Z",
          "iopub.status.busy": "2024-02-15T11:34:39.108624Z",
          "iopub.status.idle": "2024-02-15T11:34:39.955360Z",
          "shell.execute_reply": "2024-02-15T11:34:39.954584Z",
          "shell.execute_reply.started": "2024-02-15T11:34:39.109007Z"
        },
        "id": "e0ddb399-18f4-4051-86c0-39f1c623eef5",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "# from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import copy\n",
        "import math\n",
        "import pickle\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import optuna\n",
        "import catboost as cb\n",
        "import warnings\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "warnings.filterwarnings('ignore')\n",
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d8a8c3cc",
      "metadata": {},
      "outputs": [],
      "source": [
        "class Boosting:\n",
        "\n",
        "    def __init__(self, X_train, X_val, y_train, y_val, cat_features, params = None):\n",
        "        print(\"Init...\")\n",
        "        self.X_train = X_train\n",
        "        self.X_val = X_val\n",
        "        self.y_train = y_train\n",
        "        self.y_val = y_val\n",
        "        self.cat_features = cat_features\n",
        "        self.params = params\n",
        "        self.model = None\n",
        "        self.best_params = None\n",
        "        self.top_features = None\n",
        "        self.train_pool = cb.Pool(data = X_train, label = y_train, cat_features = cat_features)\n",
        "        self.val_pool = cb.Pool(data = X_val, label = y_val, cat_features = cat_features)\n",
        "        print(\"Init Finished!\")\n",
        "\n",
        "    def train(self):\n",
        "        if self.params is None:\n",
        "            model = cb.CatBoostClassifier(\n",
        "                # learning_rate = 0.303,\n",
        "                # depth = 6,\n",
        "                # l2_leaf_reg = 2.437,\n",
        "                # random_seed = 42,\n",
        "                # min_data_in_leaf = 30,\n",
        "                # one_hot_max_size = 40,\n",
        "                # colsample_bylevel = 0.079,\n",
        "                loss_function = 'MultiClass',\n",
        "                task_type = 'CPU',\n",
        "                # iterations = 1000,\n",
        "                use_best_model = True,\n",
        "                verbose = 100,\n",
        "                thread_count = -1,\n",
        "                early_stopping_rounds = 100,\n",
        "                eval_metric = 'AUC',\n",
        "                class_weights=weits,\n",
        "                # boosting_type = 'Plain',\n",
        "                # bootstrap_type = 'MVS'\n",
        "            )\n",
        "        else:\n",
        "            self.params[\"verbose\"] = 100\n",
        "            self.params[\"iterations\"] = 1000\n",
        "            model = cb.CatBoostClassifier(**self.params)\n",
        "\n",
        "        model.fit(\n",
        "            self.train_pool,\n",
        "            eval_set = self.val_pool\n",
        "        )\n",
        "        self.model = model\n",
        "        # y_train_pred = model.predict_proba(self.X_train)[:, 1]\n",
        "        # y_val_pred = model.predict_proba(self.X_val)[:, 1]\n",
        "\n",
        "        # roc_auc_tr = roc_auc_score(self.y_train, y_train_pred)\n",
        "        # roc_auc_val = roc_auc_score(self.y_val, y_val_pred)\n",
        "\n",
        "        # print(\"ROC AUC на обучающей выборке:\", roc_auc_tr)\n",
        "        # print(\"ROC AUC на валидационной выборке:\", roc_auc_val)\n",
        "\n",
        "\n",
        "    def optimize_hyperparams(self):\n",
        "\n",
        "        def objective(trial):\n",
        "            params = {\n",
        "                \"objective\" : trial.suggest_categorical(\"objective\", [\"MultiClass\"]),\n",
        "                \"learning_rate\" : trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e0),\n",
        "                \"l2_leaf_reg\" : trial.suggest_loguniform(\"l2_leaf_reg\", 1e-2, 3e0),\n",
        "                \"colsample_bylevel\" : trial.suggest_float(\"colsample_bylevel\", 0.01, 0.1, log = True),\n",
        "                \"depth\" : trial.suggest_int(\"depth\", 2, 5),\n",
        "                \"boosting_type\" : trial.suggest_categorical(\"boosting_type\", [\"Ordered\", \"Plain\"]),\n",
        "                \"bootstrap_type\" : trial.suggest_categorical(\"bootstrap_type\", [\"Bayesian\", \"Bernoulli\", \"MVS\"]),\n",
        "                \"min_data_in_leaf\" : trial.suggest_int(\"min_data_in_leaf\", 2, 50),\n",
        "                \"one_hot_max_size\" : trial.suggest_int(\"one_hot_max_size\", 2, 50),\n",
        "                \"iterations\" : trial.suggest_int(\"iterations\", 500, 3500),\n",
        "                \"eval_metric\" : \"AUC\"\n",
        "            }\n",
        "\n",
        "            if params[\"bootstrap_type\"] == \"Bayesian\":\n",
        "                params[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0, 10)\n",
        "            elif params[\"bootstrap_type\"] == \"Bernoulli\":\n",
        "                params[\"subsample\"] = trial.suggest_float(\"subsample\", 0.1, 1, log = True)\n",
        "\n",
        "            model = cb.CatBoostClassifier(\n",
        "                loss_function = 'Logloss',\n",
        "                random_seed = 42,\n",
        "                task_type = 'CPU',\n",
        "                use_best_model = True,\n",
        "                verbose = False,\n",
        "                **params\n",
        "            )\n",
        "\n",
        "            model.fit(\n",
        "                self.train_pool,\n",
        "                eval_set = self.val_pool\n",
        "            )\n",
        "\n",
        "            y_pred = model.predict_proba(self.X_val)[:, 1]\n",
        "\n",
        "            roc_auc = roc_auc_score(self.y_val, y_pred)\n",
        "\n",
        "            return roc_auc\n",
        "\n",
        "        study = optuna.create_study(pruner=optuna.pruners.MedianPruner(n_warmup_steps = 5), direction = \"maximize\")\n",
        "        study.optimize(objective, n_trials = 10, timeout = 60)\n",
        "\n",
        "        self.best_params = study.best_params\n",
        "\n",
        "        print(\"Best params:\", self.best_params)\n",
        "\n",
        "    def load_model(self, file_path):\n",
        "        with open(file_path, \"rb\") as f:\n",
        "            self.model = pickle.load(f)\n",
        "\n",
        "    def save_model(self, file_path):\n",
        "        with open(file_path, \"wb\") as f:\n",
        "            pickle.dump(self.model, f)\n",
        "\n",
        "    def show_feats_imp(self):\n",
        "        if self.model is None:\n",
        "            raise ValueError(\"Model not found!\")\n",
        "\n",
        "        feature_importance = self.model.feature_importances_\n",
        "        sorted_idx = np.argsort(feature_importance)\n",
        "\n",
        "        plt.figure(figsize=(15, 10))\n",
        "        plt.barh(range(len(sorted_idx)), feature_importance[sorted_idx], align='center')\n",
        "        plt.yticks(range(len(sorted_idx)), np.array(self.model.feature_names_)[sorted_idx])\n",
        "        plt.title(\"Feature Importance\")\n",
        "        plt.show()\n",
        "\n",
        "        self.top_features = np.flip(np.array(self.model.feature_names_)[sorted_idx])\n",
        "        print(self.top_features)\n",
        "\n",
        "    def top_feats_selection(self):\n",
        "\n",
        "        top = []\n",
        "        roc_tr = []\n",
        "        roc_val = []\n",
        "\n",
        "        for col in tqdm(self.top_features):\n",
        "\n",
        "            top.append(col)\n",
        "            top_cat = list(set(self.cat_features) & set(top))\n",
        "\n",
        "            train_pool = cb.Pool(data = self.X_train[top], label = self.y_train, cat_features = top_cat)\n",
        "            val_pool = cb.Pool(data = self.X_val[top], label = self.y_val, cat_features = top_cat)\n",
        "\n",
        "            if self.params is None:\n",
        "                model = cb.CatBoostClassifier(\n",
        "                    learning_rate = 0.303,\n",
        "                    depth = 6,\n",
        "                    l2_leaf_reg = 2.437,\n",
        "                    random_seed = 42,\n",
        "                    min_data_in_leaf = 30,\n",
        "                    one_hot_max_size = 40,\n",
        "                    colsample_bylevel = 0.079,\n",
        "                    loss_function = 'MultiClass',\n",
        "                    task_type = 'CPU',\n",
        "                    iterations = 1000,\n",
        "                    use_best_model = True,\n",
        "                    verbose = 100,\n",
        "                    thread_count = -1,\n",
        "                    early_stopping_rounds = 100,\n",
        "                    eval_metric = 'AUC',\n",
        "                    class_weights=weits,\n",
        "                    boosting_type = 'Plain',\n",
        "                    bootstrap_type = 'MVS'\n",
        "                )\n",
        "                path = \"no_optuna_top_features.xlsx\"\n",
        "            else:\n",
        "                self.params[\"verbose\"] = 0\n",
        "                self.params[\"iterations\"] = 500\n",
        "                path = \"optuna_top_features.xlsx\"\n",
        "                model = cb.CatBoostClassifier(**self.params)\n",
        "\n",
        "            model.fit(\n",
        "                train_pool,\n",
        "                eval_set = val_pool\n",
        "            )\n",
        "\n",
        "            y_train_pred = model.predict_proba(self.X_train[top])[:, 1]\n",
        "            y_val_pred = model.predict_proba(self.X_val[top])[:, 1]\n",
        "\n",
        "            roc_auc_tr = roc_auc_score(self.y_train, y_train_pred)\n",
        "            roc_auc_val = roc_auc_score(self.y_val, y_val_pred)\n",
        "\n",
        "            roc_tr.append(roc_auc_tr)\n",
        "            roc_val.append(roc_auc_val)\n",
        "\n",
        "        plt.figure(figsize=(15, 10))\n",
        "        plt.plot(range(len(self.top_features)), roc_tr, marker = 'o', label = 'Train')\n",
        "        plt.plot(range(len(self.top_features)), roc_val, marker = 'o', label = 'Valid')\n",
        "        plt.xlabel(\"Number of Top Features\")\n",
        "        plt.ylabel(\"ROC AUC\")\n",
        "        plt.title(\"ROC AUC on Top-K Features\")\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "        stats = pd.DataFrame({\n",
        "            \"TRAIN\" : roc_tr,\n",
        "            \"VALID\" : roc_val\n",
        "        })\n",
        "\n",
        "        stats.to_excel(path, index = False)\n",
        "\n",
        "    def one_factor_roc(self):\n",
        "        story = pd.DataFrame()\n",
        "\n",
        "        for feature in tqdm(self.X_train.columns):\n",
        "            if self.params is None:\n",
        "                model = cb.CatBoostClassifier(\n",
        "                    learning_rate = 0.303,\n",
        "                    depth = 6,\n",
        "                    l2_leaf_reg = 2.437,\n",
        "                    random_seed = 42,\n",
        "                    min_data_in_leaf = 30,\n",
        "                    one_hot_max_size = 40,\n",
        "                    colsample_bylevel = 0.079,\n",
        "                    loss_function = 'MultiClass',\n",
        "                    task_type = 'CPU',\n",
        "                    iterations = 1000,\n",
        "                    use_best_model = True,\n",
        "                    verbose = 100,\n",
        "                    thread_count = -1,\n",
        "                    early_stopping_rounds = 100,\n",
        "                    eval_metric = 'AUC',\n",
        "                    class_weights=weits,\n",
        "                    boosting_type = 'Plain',\n",
        "                    bootstrap_type = 'MVS'\n",
        "                )\n",
        "                path = \"no_optuna_one_factor_roc.xlsx\"\n",
        "            else:\n",
        "                self.params[\"verbose\"] = False\n",
        "                self.params[\"iterations\"] = 500\n",
        "                path = \"optuna_one_factor_roc.xlsx\"\n",
        "                model = cb.CatBoostClassifier(**self.params)\n",
        "\n",
        "            if feature in self.cat_features:\n",
        "                train_pool = cb.Pool(data = self.X_train[[feature]], label = self.y_train, cat_features = [feature])\n",
        "                val_pool = cb.Pool(data = self.X_val[[feature]], label = self.y_val, cat_features = [feature])\n",
        "            else:\n",
        "                train_pool = cb.Pool(data = self.X_train[[feature]], label = self.y_train)\n",
        "                val_pool = cb.Pool(data = self.X_val[[feature]], label = self.y_val)\n",
        "\n",
        "            model.fit(\n",
        "                train_pool,\n",
        "                eval_set = val_pool\n",
        "            )\n",
        "\n",
        "            y_train_pred = model.predict_proba(self.X_train[[feature]])[:, 1]\n",
        "            y_val_pred = model.predict_proba(self.X_val[[feature]])[:, 1]\n",
        "\n",
        "            roc_auc_tr = roc_auc_score(self.y_train, y_train_pred)\n",
        "            roc_auc_val = roc_auc_score(self.y_val, y_val_pred)\n",
        "\n",
        "            story = story.append(pd.DataFrame({\n",
        "                'features' : [feature],\n",
        "                'train' : [roc_auc_tr],\n",
        "                'valid' : [roc_auc_val]\n",
        "            }), ignore_index = True)\n",
        "\n",
        "        plt.figure(figsize=(10, 7))\n",
        "        plt.bar(range(len(story['features'])), story['train'], align = 'center', label = 'Train')\n",
        "        plt.bar(range(len(story['features'])), story['valid'], align = 'edge', label = 'Valid')\n",
        "        plt.xlabel(\"Features\")\n",
        "        plt.ylabel(\"ROC-AUC\")\n",
        "        plt.title(\"One-Factor ROC-AUC\")\n",
        "        plt.xticks(range(len(story['features'])), story['features'], rotation = 45)\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        story.to_excel(path, index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "WremRMspEMJA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WremRMspEMJA",
        "outputId": "6842e845-8079-4b49-d71e-01a31d47b1e8"
      },
      "outputs": [],
      "source": [
        "# !pip freeze | grep \"numpy\\|pandas\\|lightgbm\\|scikit-learn\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbcf3aae-5417-42a3-9ed2-818b9aef0f2f",
      "metadata": {
        "id": "cbcf3aae-5417-42a3-9ed2-818b9aef0f2f"
      },
      "source": [
        "## Загрузка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "32c8b1b0-f95e-4cb5-bbc1-c0edb76568c1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-15T11:34:44.750723Z",
          "iopub.status.busy": "2024-02-15T11:34:44.750145Z",
          "iopub.status.idle": "2024-02-15T11:34:46.098228Z",
          "shell.execute_reply": "2024-02-15T11:34:46.097494Z",
          "shell.execute_reply.started": "2024-02-15T11:34:44.750694Z"
        },
        "id": "32c8b1b0-f95e-4cb5-bbc1-c0edb76568c1",
        "tags": []
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_parquet(\"train_data.pqt\")\n",
        "test_df = pd.read_parquet(\"test_df.pqt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06044363",
      "metadata": {},
      "source": [
        "заполянем 5 месяцем"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "70f9cc0b",
      "metadata": {},
      "outputs": [],
      "source": [
        "test_df['start_cluster'] = test_df['start_cluster'].fillna(method='ffill')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69d48a01",
      "metadata": {},
      "source": [
        "вытягиваем в колбасу по id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a38b5b6b",
      "metadata": {},
      "outputs": [],
      "source": [
        "grouped_df_first = test_df.groupby('id').first().reset_index()\n",
        "merged_df = pd.merge(test_df, grouped_df_first, on='id', suffixes=('', '_first'))\n",
        "\n",
        "grouped_df_second = test_df.groupby('id').nth(1).reset_index()\n",
        "merged_df = pd.merge(merged_df, grouped_df_second, on='id', suffixes=('', '_second'))\n",
        "\n",
        "merged_df = merged_df.loc[:, ~merged_df.columns.duplicated()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "45e22331",
      "metadata": {},
      "outputs": [],
      "source": [
        "test_df = merged_df[merged_df['date'] == 'month_6']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "81f271d2",
      "metadata": {},
      "outputs": [],
      "source": [
        "grouped_df_first = train_df.groupby('id').first().reset_index()\n",
        "merged_df = pd.merge(train_df, grouped_df_first, on='id', suffixes=('', '_first'))\n",
        "\n",
        "grouped_df_second = train_df.groupby('id').nth(1).reset_index()\n",
        "merged_df = pd.merge(merged_df, grouped_df_second, on='id', suffixes=('', '_second'))\n",
        "\n",
        "merged_df = merged_df.loc[:, ~merged_df.columns.duplicated()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "99ce934c",
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'merged_df' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_df \u001b[38;5;241m=\u001b[39m \u001b[43mmerged_df\u001b[49m[merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonth_3\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
            "\u001b[1;31mNameError\u001b[0m: name 'merged_df' is not defined"
          ]
        }
      ],
      "source": [
        "train_df = merged_df[merged_df['date'] == 'month_3']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c22b60ce",
      "metadata": {},
      "source": [
        "удаляем сильную корреляцию"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "cbe87424",
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_matrix = train_df.corr().abs()\n",
        "\n",
        "# Получение верхнего треугольника матрицы корреляции (без диагонали)\n",
        "upper_triangle = corr_matrix.where(\n",
        "    np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
        "\n",
        "# Нахождение колонок, где корреляция больше 0.9\n",
        "to_drop = [column for column in upper_triangle.columns if any(upper_triangle[column] > 0.95)]\n",
        "\n",
        "train_df =train_df.drop(to_drop, axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "ec78c3b5",
      "metadata": {},
      "outputs": [],
      "source": [
        "test_df =test_df.drop(to_drop, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e50a2c22",
      "metadata": {},
      "outputs": [],
      "source": [
        "category_columns = ['start_cluster', 'channel_code', 'city', 'city_type', \n",
        "                    'index_city_code', 'ogrn_month', 'ogrn_year', 'okved', 'segment']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "fdf0c11c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# counts = train_df['city_type'].value_counts()\n",
        "\n",
        "# # Построение гистограммы\n",
        "# plt.bar(counts.index, counts.values)\n",
        "# plt.xlabel('Уникальные значения')\n",
        "# plt.ylabel('Частота')\n",
        "# plt.title('Гистограмма количества встречающихся раз категориальных значений')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0dae8244",
      "metadata": {},
      "source": [
        "обработка текстов и нан"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "c77de816",
      "metadata": {},
      "outputs": [],
      "source": [
        "def clever_one_hot(df, col): #переписать в lable encoding?\n",
        "    top_4 = df[col].value_counts().index[:4]\n",
        "    df.loc[~df[col].isin(top_4), col] = 'other'\n",
        "    one_hot_encoded = pd.get_dummies(df[col], prefix=col)\n",
        "    df = df.drop(col, axis=1)\n",
        "    return pd.concat([df, one_hot_encoded], axis=1)\n",
        "\n",
        "def feature_prossesing(df):\n",
        "    one_hot_encoded = pd.get_dummies(df['segment'], prefix='seg')\n",
        "    df = df.drop('segment', axis=1)\n",
        "    df = pd.concat([df, one_hot_encoded], axis=1)\n",
        "\n",
        "    df['ogrn_year'] = df['ogrn_year'].fillna('_-1')\n",
        "    df['ogrn_month'] = df['ogrn_month'].fillna('_-1')\n",
        "    df['ogrn_year'] = df['ogrn_year'].apply(lambda x: int(x.split('_')[-1]))\n",
        "    df['ogrn_month'] = df['ogrn_month'].apply(lambda x: int(x.split('_')[-1]))\n",
        "    df['lasting'] = df['ogrn_year']*12 + df['ogrn_month']\n",
        "    df['lasting'] = df['lasting'].apply(lambda x: x if x>=0 else -1)\n",
        "\n",
        "    del df['ogrn_year']\n",
        "    del df['ogrn_month']\n",
        "\n",
        "    for i in ['channel_code', 'city_type']:\n",
        "        df = clever_one_hot(df, i)\n",
        "\n",
        "    label_encoder = LabelEncoder()\n",
        "    df['start_cluster'] = label_encoder.fit_transform(df['start_cluster'])\n",
        "    df['end_cluster'] = label_encoder.transform(df['end_cluster'])\n",
        "    category_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
        "\n",
        "    df = df.drop(df.select_dtypes(include=['object']).columns, axis=1)\n",
        "    df = df.fillna(-1)\n",
        "\n",
        "    return df, category_mapping   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "571718d7",
      "metadata": {},
      "outputs": [],
      "source": [
        "df, category_mapping = feature_prossesing(train_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "db0e4abe",
      "metadata": {},
      "outputs": [],
      "source": [
        "def clever_one_hot(df, col, df1): #переписать в lable encoding?\n",
        "    top_4 = df1[col].value_counts().index[:4]\n",
        "    df.loc[~df[col].isin(top_4), col] = 'other'\n",
        "    one_hot_encoded = pd.get_dummies(df[col], prefix=col)\n",
        "    df = df.drop(col, axis=1)\n",
        "    return pd.concat([df, one_hot_encoded], axis=1)\n",
        "\n",
        "def feature_prossesing(df, df_1):\n",
        "    one_hot_encoded = pd.get_dummies(df['segment'], prefix='seg')\n",
        "    df = df.drop('segment', axis=1)\n",
        "    df = pd.concat([df, one_hot_encoded], axis=1)\n",
        "\n",
        "    df['ogrn_year'] = df['ogrn_year'].fillna('_-1')\n",
        "    df['ogrn_month'] = df['ogrn_month'].fillna('_-1')\n",
        "    df['ogrn_year'] = df['ogrn_year'].apply(lambda x: int(x.split('_')[-1]))\n",
        "    df['ogrn_month'] = df['ogrn_month'].apply(lambda x: int(x.split('_')[-1]))\n",
        "    df['lasting'] = df['ogrn_year']*12 + df['ogrn_month']\n",
        "    df['lasting'] = df['lasting'].apply(lambda x: x if x>=0 else -1)\n",
        "\n",
        "    del df['ogrn_year']\n",
        "    del df['ogrn_month']\n",
        "\n",
        "    for i in ['channel_code', 'city_type']:\n",
        "        df = clever_one_hot(df, i, df_1)\n",
        "\n",
        "    label_encoder = LabelEncoder()\n",
        "    df['start_cluster'] = label_encoder.fit_transform(df['start_cluster'])\n",
        "    #df['end_cluster'] = label_encoder.transform(df['end_cluster'])\n",
        "    category_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
        "\n",
        "    df = df.drop(df.select_dtypes(include=['object']).columns, axis=1)\n",
        "    df = df.fillna(-1)\n",
        "\n",
        "    return df, category_mapping   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "fb386861",
      "metadata": {},
      "outputs": [],
      "source": [
        "test, category_mapping = feature_prossesing(test_df, train_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "78538828",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'{other}': 0,\n",
              " '{}': 1,\n",
              " '{α, β}': 2,\n",
              " '{α, γ}': 3,\n",
              " '{α, δ}': 4,\n",
              " '{α, ε, η}': 5,\n",
              " '{α, ε, θ}': 6,\n",
              " '{α, ε, ψ}': 7,\n",
              " '{α, ε}': 8,\n",
              " '{α, η}': 9,\n",
              " '{α, θ}': 10,\n",
              " '{α, λ}': 11,\n",
              " '{α, μ}': 12,\n",
              " '{α, ψ}': 13,\n",
              " '{α}': 14,\n",
              " '{λ}': 15}"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "category_mapping"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "791378ad",
      "metadata": {},
      "source": [
        "веса для рок аука которые идут в бустинг"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "1c966fbb",
      "metadata": {},
      "outputs": [],
      "source": [
        "def weighted_roc_auc(y_true, y_pred, labels, weights_dict):\n",
        "    unnorm_weights = np.array([weights_dict[label] for label in labels])\n",
        "    weights = unnorm_weights / unnorm_weights.sum()\n",
        "    classes_roc_auc = roc_auc_score(y_true, y_pred, labels=labels,\n",
        "                                    multi_class=\"ovr\", average=None)\n",
        "    return sum(weights * classes_roc_auc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "67791ff1",
      "metadata": {},
      "outputs": [],
      "source": [
        "cluster_weights = pd.read_excel(\"cluster_weights.xlsx\").set_index(\"cluster\")\n",
        "weights_dict = cluster_weights[\"unnorm_weight\"].to_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "b6ea63c8",
      "metadata": {},
      "outputs": [],
      "source": [
        "weits = [0]*17\n",
        "\n",
        "for k, v in category_mapping.items():\n",
        "    weits[category_mapping[k]] = weights_dict[k]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "ec1aaf24",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[3, 1, 3, 3, 3, 1, 1, 3, 2, 2, 1, 3, 2, 3, 2, 2, 0]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weits"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91feaa10",
      "metadata": {},
      "source": [
        "треним"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "a81d6e35",
      "metadata": {},
      "outputs": [],
      "source": [
        "y = df['end_cluster']\n",
        "X = df.drop(['end_cluster'], axis=1)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "c47ced68",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Init...\n",
            "Init Finished!\n"
          ]
        }
      ],
      "source": [
        "boosting = Boosting(X_train, X_val, y_train, y_val, cat_features = [])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "9e95a724",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Learning rate set to 0.119794\n",
            "0:\ttest: 0.8082294\tbest: 0.8082294 (0)\ttotal: 2.09s\tremaining: 34m 47s\n",
            "100:\ttest: 0.9312565\tbest: 0.9332134 (94)\ttotal: 6m 18s\tremaining: 56m 9s\n",
            "200:\ttest: 0.9329724\tbest: 0.9338155 (118)\ttotal: 11m 58s\tremaining: 47m 34s\n",
            "Stopped by overfitting detector  (100 iterations wait)\n",
            "\n",
            "bestTest = 0.9338154824\n",
            "bestIteration = 118\n",
            "\n",
            "Shrink model to first 119 iterations.\n"
          ]
        }
      ],
      "source": [
        "boosting.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aeda601a",
      "metadata": {},
      "source": [
        "сохраняем загружаем"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "bf52d538",
      "metadata": {},
      "outputs": [],
      "source": [
        "boosting.save_model('model2.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "533e53f7",
      "metadata": {},
      "outputs": [],
      "source": [
        "boosting.load_model('model2.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7e0150e",
      "metadata": {},
      "source": [
        "получаем ответ на тесте"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "1b28c8c2",
      "metadata": {},
      "outputs": [],
      "source": [
        "ans = boosting.model.predict_proba(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "66d8f2b4",
      "metadata": {},
      "outputs": [],
      "source": [
        "data = {} #{'id': test.id.to_list()}\n",
        "for cls, prob in zip(category_mapping.keys(), ans):\n",
        "    data[cls] = prob\n",
        "\n",
        "column_mapping = {\n",
        "    0: '{other}',\n",
        "    1: '{}',\n",
        "    2: '{α, β}',\n",
        "    3: '{α, γ}',\n",
        "    4: '{α, δ}',\n",
        "    5: '{α, ε, η}',\n",
        "    6: '{α, ε, θ}',\n",
        "    7: '{α, ε, ψ}',\n",
        "    8: '{α, ε}',\n",
        "    9: '{α, η}',\n",
        "    10: '{α, θ}',\n",
        "    11: '{α, λ}',\n",
        "    12: '{α, μ}',\n",
        "    13: '{α, π}',\n",
        "    14: '{α, ψ}',\n",
        "    15: '{α}',\n",
        "    16: '{λ}'\n",
        "}\n",
        "\n",
        "output = pd.DataFrame(ans)\n",
        "output = output.rename(columns=column_mapping)\n",
        "output = output.assign(id=test['id'].tolist())\n",
        "\n",
        "sample_submission_df = pd.read_csv(\"sample_submission.csv\")\n",
        "output[list(sample_submission_df.columns)].to_csv('ans3.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d61ae3af",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['id',\n",
              " '{other}',\n",
              " '{}',\n",
              " '{α, β}',\n",
              " '{α, γ}',\n",
              " '{α, δ}',\n",
              " '{α, ε, η}',\n",
              " '{α, ε, θ}',\n",
              " '{α, ε, ψ}',\n",
              " '{α, ε}',\n",
              " '{α, η}',\n",
              " '{α, θ}',\n",
              " '{α, λ}',\n",
              " '{α, μ}',\n",
              " '{α, π}',\n",
              " '{α, ψ}',\n",
              " '{α}',\n",
              " '{λ}']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "sample_submission_df = pd.read_csv(\"sample_submission.csv\")\n",
        "list(sample_submission_df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1a205b27",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "e4ead55ff0a49c8ee3cc879f2470f4d9\n"
          ]
        }
      ],
      "source": [
        "import hashlib\n",
        "\n",
        "def generate_md5(file_path):\n",
        "    # Open the file in binary mode\n",
        "    with open(file_path, \"rb\") as file:\n",
        "        # Read the content of the file\n",
        "        content = file.read()\n",
        "        # Generate the MD5 hash of the content\n",
        "        md5_hash = hashlib.md5(content).hexdigest()\n",
        "        return md5_hash\n",
        "\n",
        "# Call the function to generate the MD5 hash of a video file\n",
        "# Replace \"video.mp4\" with the path to your video file\n",
        "md5_hash = generate_md5(r\"C:\\Users\\alina\\Videos\\2024-03-12 14-31-10.mkv\")\n",
        "\n",
        "# Print the MD5 hash\n",
        "print(md5_hash)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3221f313",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "python3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
