{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8b7bef09-9e86-4b19-bbb7-e0ccb7515328",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-14T22:50:38.627643Z",
          "iopub.status.busy": "2024-02-14T22:50:38.627255Z",
          "iopub.status.idle": "2024-02-14T22:50:39.496067Z",
          "shell.execute_reply": "2024-02-14T22:50:39.495215Z",
          "shell.execute_reply.started": "2024-02-14T22:50:38.627616Z"
        },
        "id": "8b7bef09-9e86-4b19-bbb7-e0ccb7515328",
        "tags": []
      },
      "source": [
        "# Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "e0ddb399-18f4-4051-86c0-39f1c623eef5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-15T11:34:39.109032Z",
          "iopub.status.busy": "2024-02-15T11:34:39.108624Z",
          "iopub.status.idle": "2024-02-15T11:34:39.955360Z",
          "shell.execute_reply": "2024-02-15T11:34:39.954584Z",
          "shell.execute_reply.started": "2024-02-15T11:34:39.109007Z"
        },
        "id": "e0ddb399-18f4-4051-86c0-39f1c623eef5",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "# from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import copy\n",
        "import math\n",
        "import pickle\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import optuna\n",
        "import catboost as cb\n",
        "import warnings\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "warnings.filterwarnings('ignore')\n",
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "d8a8c3cc",
      "metadata": {},
      "outputs": [],
      "source": [
        "class Boosting:\n",
        "\n",
        "    def __init__(self, X_train, X_val, y_train, y_val, cat_features, params = None):\n",
        "        print(\"Init...\")\n",
        "        self.X_train = X_train\n",
        "        self.X_val = X_val\n",
        "        self.y_train = y_train\n",
        "        self.y_val = y_val\n",
        "        self.cat_features = cat_features\n",
        "        self.params = params\n",
        "        self.model = None\n",
        "        self.best_params = None\n",
        "        self.top_features = None\n",
        "        self.train_pool = cb.Pool(data = X_train, label = y_train, cat_features = cat_features)\n",
        "        self.val_pool = cb.Pool(data = X_val, label = y_val, cat_features = cat_features)\n",
        "        print(\"Init Finished!\")\n",
        "\n",
        "    def train(self):\n",
        "        if self.params is None:\n",
        "            model = cb.CatBoostClassifier(\n",
        "                # learning_rate = 0.303,\n",
        "                # depth = 6,\n",
        "                # l2_leaf_reg = 2.437,\n",
        "                # random_seed = 42,\n",
        "                # min_data_in_leaf = 30,\n",
        "                # one_hot_max_size = 40,\n",
        "                # colsample_bylevel = 0.079,\n",
        "                loss_function = 'MultiClass',\n",
        "                task_type = 'CPU',\n",
        "                iterations = 1000,\n",
        "                use_best_model = True,\n",
        "                verbose = 100,\n",
        "                thread_count = -1,\n",
        "                early_stopping_rounds = 100,\n",
        "                eval_metric = 'AUC',\n",
        "                class_weights=weits,\n",
        "                # boosting_type = 'Plain',\n",
        "                # bootstrap_type = 'MVS'\n",
        "            )\n",
        "            self.load_model('model4_new_coding_nocorr.pkl')\n",
        "        else:\n",
        "            self.params[\"verbose\"] = 100\n",
        "            self.params[\"iterations\"] = 1000\n",
        "            model = cb.CatBoostClassifier(**self.params)\n",
        "\n",
        "        self.model.fit(\n",
        "            self.train_pool,\n",
        "            eval_set = self.val_pool\n",
        "        )\n",
        "        # self.model = model\n",
        "        # # y_train_pred = model.predict_proba(self.X_train)[:, 1]\n",
        "        # y_val_pred = model.predict_proba(self.X_val)[:, 1]\n",
        "\n",
        "        # roc_auc_tr = roc_auc_score(self.y_train, y_train_pred)\n",
        "        # roc_auc_val = roc_auc_score(self.y_val, y_val_pred)\n",
        "\n",
        "        # print(\"ROC AUC на обучающей выборке:\", roc_auc_tr)\n",
        "        # print(\"ROC AUC на валидационной выборке:\", roc_auc_val)\n",
        "\n",
        "\n",
        "    def optimize_hyperparams(self):\n",
        "\n",
        "        def objective(trial):\n",
        "            params = {\n",
        "                \"objective\" : trial.suggest_categorical(\"objective\", [\"MultiClass\"]),\n",
        "                \"learning_rate\" : trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e0),\n",
        "                \"l2_leaf_reg\" : trial.suggest_loguniform(\"l2_leaf_reg\", 1e-2, 3e0),\n",
        "                \"colsample_bylevel\" : trial.suggest_float(\"colsample_bylevel\", 0.01, 0.1, log = True),\n",
        "                \"depth\" : trial.suggest_int(\"depth\", 2, 5),\n",
        "                \"boosting_type\" : trial.suggest_categorical(\"boosting_type\", [\"Ordered\", \"Plain\"]),\n",
        "                \"bootstrap_type\" : trial.suggest_categorical(\"bootstrap_type\", [\"Bayesian\", \"Bernoulli\", \"MVS\"]),\n",
        "                \"min_data_in_leaf\" : trial.suggest_int(\"min_data_in_leaf\", 2, 50),\n",
        "                \"one_hot_max_size\" : trial.suggest_int(\"one_hot_max_size\", 2, 50),\n",
        "                \"iterations\" : trial.suggest_int(\"iterations\", 500, 3500),\n",
        "                \"eval_metric\" : \"AUC\"\n",
        "            }\n",
        "\n",
        "            if params[\"bootstrap_type\"] == \"Bayesian\":\n",
        "                params[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0, 10)\n",
        "            elif params[\"bootstrap_type\"] == \"Bernoulli\":\n",
        "                params[\"subsample\"] = trial.suggest_float(\"subsample\", 0.1, 1, log = True)\n",
        "\n",
        "            model = cb.CatBoostClassifier(\n",
        "                loss_function = 'Logloss',\n",
        "                random_seed = 42,\n",
        "                task_type = 'CPU',\n",
        "                use_best_model = True,\n",
        "                verbose = False,\n",
        "                **params\n",
        "            )\n",
        "\n",
        "            model.fit(\n",
        "                self.train_pool,\n",
        "                eval_set = self.val_pool\n",
        "            )\n",
        "\n",
        "            y_pred = model.predict_proba(self.X_val)[:, 1]\n",
        "\n",
        "            roc_auc = roc_auc_score(self.y_val, y_pred)\n",
        "\n",
        "            return roc_auc\n",
        "\n",
        "        study = optuna.create_study(pruner=optuna.pruners.MedianPruner(n_warmup_steps = 5), direction = \"maximize\")\n",
        "        study.optimize(objective, n_trials = 10, timeout = 60)\n",
        "\n",
        "        self.best_params = study.best_params\n",
        "\n",
        "        print(\"Best params:\", self.best_params)\n",
        "\n",
        "    def load_model(self, file_path):\n",
        "        with open(file_path, \"rb\") as f:\n",
        "            self.model = pickle.load(f)\n",
        "\n",
        "    def save_model(self, file_path):\n",
        "        with open(file_path, \"wb\") as f:\n",
        "            pickle.dump(self.model, f)\n",
        "\n",
        "    def show_feats_imp(self):\n",
        "        if self.model is None:\n",
        "            raise ValueError(\"Model not found!\")\n",
        "\n",
        "        feature_importance = self.model.feature_importances_\n",
        "        sorted_idx = np.argsort(feature_importance)\n",
        "\n",
        "        plt.figure(figsize=(15, 10))\n",
        "        plt.barh(range(len(sorted_idx)), feature_importance[sorted_idx], align='center')\n",
        "        plt.yticks(range(len(sorted_idx)), np.array(self.model.feature_names_)[sorted_idx])\n",
        "        plt.title(\"Feature Importance\")\n",
        "        plt.show()\n",
        "\n",
        "        self.top_features = np.flip(np.array(self.model.feature_names_)[sorted_idx])\n",
        "        print(self.top_features)\n",
        "\n",
        "    def top_feats_selection(self):\n",
        "\n",
        "        top = []\n",
        "        roc_tr = []\n",
        "        roc_val = []\n",
        "\n",
        "        for col in tqdm(self.top_features):\n",
        "\n",
        "            top.append(col)\n",
        "            top_cat = list(set(self.cat_features) & set(top))\n",
        "\n",
        "            train_pool = cb.Pool(data = self.X_train[top], label = self.y_train, cat_features = top_cat)\n",
        "            val_pool = cb.Pool(data = self.X_val[top], label = self.y_val, cat_features = top_cat)\n",
        "\n",
        "            if self.params is None:\n",
        "                model = cb.CatBoostClassifier(\n",
        "                    learning_rate = 0.303,\n",
        "                    depth = 6,\n",
        "                    l2_leaf_reg = 2.437,\n",
        "                    random_seed = 42,\n",
        "                    min_data_in_leaf = 30,\n",
        "                    one_hot_max_size = 40,\n",
        "                    colsample_bylevel = 0.079,\n",
        "                    loss_function = 'MultiClass',\n",
        "                    task_type = 'CPU',\n",
        "                    iterations = 1000,\n",
        "                    use_best_model = True,\n",
        "                    verbose = 100,\n",
        "                    thread_count = -1,\n",
        "                    early_stopping_rounds = 100,\n",
        "                    eval_metric = 'AUC',\n",
        "                    class_weights=weits,\n",
        "                    boosting_type = 'Plain',\n",
        "                    bootstrap_type = 'MVS'\n",
        "                )\n",
        "                path = \"no_optuna_top_features.xlsx\"\n",
        "            else:\n",
        "                self.params[\"verbose\"] = 0\n",
        "                self.params[\"iterations\"] = 500\n",
        "                path = \"optuna_top_features.xlsx\"\n",
        "                model = cb.CatBoostClassifier(**self.params)\n",
        "\n",
        "            model.fit(\n",
        "                train_pool,\n",
        "                eval_set = val_pool\n",
        "            )\n",
        "\n",
        "            y_train_pred = model.predict_proba(self.X_train[top])[:, 1]\n",
        "            y_val_pred = model.predict_proba(self.X_val[top])[:, 1]\n",
        "\n",
        "            roc_auc_tr = roc_auc_score(self.y_train, y_train_pred)\n",
        "            roc_auc_val = roc_auc_score(self.y_val, y_val_pred)\n",
        "\n",
        "            roc_tr.append(roc_auc_tr)\n",
        "            roc_val.append(roc_auc_val)\n",
        "\n",
        "        plt.figure(figsize=(15, 10))\n",
        "        plt.plot(range(len(self.top_features)), roc_tr, marker = 'o', label = 'Train')\n",
        "        plt.plot(range(len(self.top_features)), roc_val, marker = 'o', label = 'Valid')\n",
        "        plt.xlabel(\"Number of Top Features\")\n",
        "        plt.ylabel(\"ROC AUC\")\n",
        "        plt.title(\"ROC AUC on Top-K Features\")\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "        stats = pd.DataFrame({\n",
        "            \"TRAIN\" : roc_tr,\n",
        "            \"VALID\" : roc_val\n",
        "        })\n",
        "\n",
        "        stats.to_excel(path, index = False)\n",
        "\n",
        "    def one_factor_roc(self):\n",
        "        story = pd.DataFrame()\n",
        "\n",
        "        for feature in tqdm(self.X_train.columns):\n",
        "            if self.params is None:\n",
        "                model = cb.CatBoostClassifier(\n",
        "                    learning_rate = 0.303,\n",
        "                    depth = 6,\n",
        "                    l2_leaf_reg = 2.437,\n",
        "                    random_seed = 42,\n",
        "                    min_data_in_leaf = 30,\n",
        "                    one_hot_max_size = 40,\n",
        "                    colsample_bylevel = 0.079,\n",
        "                    loss_function = 'MultiClass',\n",
        "                    task_type = 'CPU',\n",
        "                    iterations = 1000,\n",
        "                    use_best_model = True,\n",
        "                    verbose = 100,\n",
        "                    thread_count = -1,\n",
        "                    early_stopping_rounds = 100,\n",
        "                    eval_metric = 'AUC',\n",
        "                    class_weights=weits,\n",
        "                    boosting_type = 'Plain',\n",
        "                    bootstrap_type = 'MVS'\n",
        "                )\n",
        "                path = \"no_optuna_one_factor_roc.xlsx\"\n",
        "            else:\n",
        "                self.params[\"verbose\"] = False\n",
        "                self.params[\"iterations\"] = 500\n",
        "                path = \"optuna_one_factor_roc.xlsx\"\n",
        "                model = cb.CatBoostClassifier(**self.params)\n",
        "\n",
        "            if feature in self.cat_features:\n",
        "                train_pool = cb.Pool(data = self.X_train[[feature]], label = self.y_train, cat_features = [feature])\n",
        "                val_pool = cb.Pool(data = self.X_val[[feature]], label = self.y_val, cat_features = [feature])\n",
        "            else:\n",
        "                train_pool = cb.Pool(data = self.X_train[[feature]], label = self.y_train)\n",
        "                val_pool = cb.Pool(data = self.X_val[[feature]], label = self.y_val)\n",
        "\n",
        "            model.fit(\n",
        "                train_pool,\n",
        "                eval_set = val_pool\n",
        "            )\n",
        "\n",
        "            y_train_pred = model.predict_proba(self.X_train[[feature]])[:, 1]\n",
        "            y_val_pred = model.predict_proba(self.X_val[[feature]])[:, 1]\n",
        "\n",
        "            roc_auc_tr = roc_auc_score(self.y_train, y_train_pred)\n",
        "            roc_auc_val = roc_auc_score(self.y_val, y_val_pred)\n",
        "\n",
        "            story = story.append(pd.DataFrame({\n",
        "                'features' : [feature],\n",
        "                'train' : [roc_auc_tr],\n",
        "                'valid' : [roc_auc_val]\n",
        "            }), ignore_index = True)\n",
        "\n",
        "        plt.figure(figsize=(10, 7))\n",
        "        plt.bar(range(len(story['features'])), story['train'], align = 'center', label = 'Train')\n",
        "        plt.bar(range(len(story['features'])), story['valid'], align = 'edge', label = 'Valid')\n",
        "        plt.xlabel(\"Features\")\n",
        "        plt.ylabel(\"ROC-AUC\")\n",
        "        plt.title(\"One-Factor ROC-AUC\")\n",
        "        plt.xticks(range(len(story['features'])), story['features'], rotation = 45)\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        story.to_excel(path, index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "WremRMspEMJA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WremRMspEMJA",
        "outputId": "6842e845-8079-4b49-d71e-01a31d47b1e8"
      },
      "outputs": [],
      "source": [
        "# !pip freeze | grep \"numpy\\|pandas\\|lightgbm\\|scikit-learn\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbcf3aae-5417-42a3-9ed2-818b9aef0f2f",
      "metadata": {
        "id": "cbcf3aae-5417-42a3-9ed2-818b9aef0f2f"
      },
      "source": [
        "## Загрузка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "32c8b1b0-f95e-4cb5-bbc1-c0edb76568c1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-15T11:34:44.750723Z",
          "iopub.status.busy": "2024-02-15T11:34:44.750145Z",
          "iopub.status.idle": "2024-02-15T11:34:46.098228Z",
          "shell.execute_reply": "2024-02-15T11:34:46.097494Z",
          "shell.execute_reply.started": "2024-02-15T11:34:44.750694Z"
        },
        "id": "32c8b1b0-f95e-4cb5-bbc1-c0edb76568c1",
        "tags": []
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_parquet(\"train_data.pqt\")\n",
        "test_df = pd.read_parquet(\"test_data.pqt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06044363",
      "metadata": {},
      "source": [
        "заполянем 5 месяцем"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "70f9cc0b",
      "metadata": {},
      "outputs": [],
      "source": [
        "test_df['start_cluster'] = test_df['start_cluster'].fillna(method='ffill')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69d48a01",
      "metadata": {},
      "source": [
        "вытягиваем в колбасу по id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "a38b5b6b",
      "metadata": {},
      "outputs": [],
      "source": [
        "grouped_df_first = test_df.groupby('id').first().reset_index()\n",
        "merged_df = pd.merge(test_df, grouped_df_first, on='id', suffixes=('', '_first'))\n",
        "\n",
        "grouped_df_second = test_df.groupby('id').nth(1).reset_index()\n",
        "merged_df = pd.merge(merged_df, grouped_df_second, on='id', suffixes=('', '_second'))\n",
        "\n",
        "merged_df = merged_df.loc[:, ~merged_df.columns.duplicated()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "45e22331",
      "metadata": {},
      "outputs": [],
      "source": [
        "test_df = merged_df[merged_df['date'] == 'month_6']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "81f271d2",
      "metadata": {},
      "outputs": [],
      "source": [
        "grouped_df_first = train_df.groupby('id').first().reset_index()\n",
        "merged_df = pd.merge(train_df, grouped_df_first, on='id', suffixes=('', '_first'))\n",
        "\n",
        "grouped_df_second = train_df.groupby('id').nth(1).reset_index()\n",
        "merged_df = pd.merge(merged_df, grouped_df_second, on='id', suffixes=('', '_second'))\n",
        "\n",
        "merged_df = merged_df.loc[:, ~merged_df.columns.duplicated()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "99ce934c",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df = merged_df[merged_df['date'] == 'month_3']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c22b60ce",
      "metadata": {},
      "source": [
        "удаляем сильную корреляцию"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "cbe87424",
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_matrix = train_df.corr().abs()\n",
        "\n",
        "# Получение верхнего треугольника матрицы корреляции (без диагонали)\n",
        "upper_triangle = corr_matrix.where(\n",
        "    np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
        "\n",
        "# Нахождение колонок, где корреляция больше 0.9\n",
        "to_drop = [column for column in upper_triangle.columns if any(upper_triangle[column] > 0.95)]\n",
        "\n",
        "train_df =train_df.drop(to_drop, axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "ec78c3b5",
      "metadata": {},
      "outputs": [],
      "source": [
        "test_df =test_df.drop(to_drop, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "e50a2c22",
      "metadata": {},
      "outputs": [],
      "source": [
        "category_columns = ['start_cluster', 'channel_code', 'city', 'city_type', \n",
        "                    'index_city_code', 'ogrn_month', 'ogrn_year', 'okved', 'segment']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "fdf0c11c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# counts = train_df['city_type'].value_counts()\n",
        "\n",
        "# # Построение гистограммы\n",
        "# plt.bar(counts.index, counts.values)\n",
        "# plt.xlabel('Уникальные значения')\n",
        "# plt.ylabel('Частота')\n",
        "# plt.title('Гистограмма количества встречающихся раз категориальных значений')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0dae8244",
      "metadata": {},
      "source": [
        "обработка текстов и нан"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "a64e1d8c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2          channel_code_5\n",
              "5          channel_code_2\n",
              "8         channel_code_12\n",
              "11        channel_code_14\n",
              "14         channel_code_8\n",
              "               ...       \n",
              "599987     channel_code_9\n",
              "599990    channel_code_14\n",
              "599993     channel_code_8\n",
              "599996     channel_code_9\n",
              "599999    channel_code_14\n",
              "Name: channel_code, Length: 200000, dtype: object"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df['channel_code']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "c77de816",
      "metadata": {},
      "outputs": [],
      "source": [
        "# def clever_one_hot(df, col): #переписать в lable encoding?\n",
        "#     top_4 = df[col].value_counts().index[:4]\n",
        "#     df.loc[~df[col].isin(top_4), col] = 'other'\n",
        "#     one_hot_encoded = pd.get_dummies(df[col], prefix=col)\n",
        "#     df = df.drop(col, axis=1)\n",
        "#     return pd.concat([df, one_hot_encoded], axis=1)\n",
        "\n",
        "def feature_prossesing(df):\n",
        "    one_hot_encoded = pd.get_dummies(df['segment'], prefix='seg')\n",
        "    df = df.drop('segment', axis=1)\n",
        "    df = pd.concat([df, one_hot_encoded], axis=1)\n",
        "\n",
        "    df['ogrn_year'] = df['ogrn_year'].fillna('_-1')\n",
        "    df['ogrn_month'] = df['ogrn_month'].fillna('_-1')\n",
        "    df['ogrn_year'] = df['ogrn_year'].apply(lambda x: int(x.split('_')[-1]))\n",
        "    df['ogrn_month'] = df['ogrn_month'].apply(lambda x: int(x.split('_')[-1]))\n",
        "    df['lasting'] = df['ogrn_year']*12 + df['ogrn_month']\n",
        "    df['lasting'] = df['lasting'].apply(lambda x: x if x>=0 else -1)\n",
        "\n",
        "    del df['ogrn_year']\n",
        "    del df['ogrn_month']\n",
        "\n",
        "    label_encoder = LabelEncoder()\n",
        "    \n",
        "\n",
        "    for i in ['channel_code', 'city_type', 'okved']:\n",
        "        df[i] = label_encoder.fit_transform(df[i])\n",
        "\n",
        "    \n",
        "    df['start_cluster'] = label_encoder.fit_transform(df['start_cluster'])\n",
        "    df['end_cluster'] = label_encoder.transform(df['end_cluster'])\n",
        "    category_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
        "\n",
        "    df = df.drop(df.select_dtypes(include=['object']).columns, axis=1)\n",
        "    df = df.fillna(-1)\n",
        "\n",
        "    return df, category_mapping   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "571718d7",
      "metadata": {},
      "outputs": [],
      "source": [
        "df, category_mapping = feature_prossesing(train_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "db0e4abe",
      "metadata": {},
      "outputs": [],
      "source": [
        "def clever_one_hot(df, col, df1): #переписать в lable encoding?\n",
        "    top_4 = df1[col].value_counts().index[:4]\n",
        "    df.loc[~df[col].isin(top_4), col] = 'other'\n",
        "    one_hot_encoded = pd.get_dummies(df[col], prefix=col)\n",
        "    df = df.drop(col, axis=1)\n",
        "    return pd.concat([df, one_hot_encoded], axis=1)\n",
        "\n",
        "def feature_prossesing(df, df_1):\n",
        "    one_hot_encoded = pd.get_dummies(df['segment'], prefix='seg')\n",
        "    df = df.drop('segment', axis=1)\n",
        "    df = pd.concat([df, one_hot_encoded], axis=1)\n",
        "\n",
        "    df['ogrn_year'] = df['ogrn_year'].fillna('_-1')\n",
        "    df['ogrn_month'] = df['ogrn_month'].fillna('_-1')\n",
        "    df['ogrn_year'] = df['ogrn_year'].apply(lambda x: int(x.split('_')[-1]))\n",
        "    df['ogrn_month'] = df['ogrn_month'].apply(lambda x: int(x.split('_')[-1]))\n",
        "    df['lasting'] = df['ogrn_year']*12 + df['ogrn_month']\n",
        "    df['lasting'] = df['lasting'].apply(lambda x: x if x>=0 else -1)\n",
        "\n",
        "    del df['ogrn_year']\n",
        "    del df['ogrn_month']\n",
        "\n",
        "    label_encoder = LabelEncoder()\n",
        "    \n",
        "\n",
        "    for i in ['channel_code', 'city_type', 'okved']:\n",
        "        df[i] = label_encoder.fit_transform(df[i])\n",
        "\n",
        "    df['start_cluster'] = label_encoder.fit_transform(df['start_cluster'])\n",
        "    #df['end_cluster'] = label_encoder.transform(df['end_cluster'])\n",
        "    category_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
        "\n",
        "    df = df.drop(df.select_dtypes(include=['object']).columns, axis=1)\n",
        "    df = df.fillna(-1)\n",
        "\n",
        "    return df, category_mapping   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "fb386861",
      "metadata": {},
      "outputs": [],
      "source": [
        "test, category_mapping = feature_prossesing(test_df, train_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "78538828",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'{other}': 0,\n",
              " '{}': 1,\n",
              " '{α, β}': 2,\n",
              " '{α, γ}': 3,\n",
              " '{α, δ}': 4,\n",
              " '{α, ε, η}': 5,\n",
              " '{α, ε, θ}': 6,\n",
              " '{α, ε, ψ}': 7,\n",
              " '{α, ε}': 8,\n",
              " '{α, η}': 9,\n",
              " '{α, θ}': 10,\n",
              " '{α, λ}': 11,\n",
              " '{α, μ}': 12,\n",
              " '{α, π}': 13,\n",
              " '{α, ψ}': 14,\n",
              " '{α}': 15,\n",
              " '{λ}': 16}"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "category_mapping"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "791378ad",
      "metadata": {},
      "source": [
        "веса для рок аука которые идут в бустинг"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "1c966fbb",
      "metadata": {},
      "outputs": [],
      "source": [
        "def weighted_roc_auc(y_true, y_pred, labels, weights_dict):\n",
        "    unnorm_weights = np.array([weights_dict[label] for label in labels])\n",
        "    weights = unnorm_weights / unnorm_weights.sum()\n",
        "    classes_roc_auc = roc_auc_score(y_true, y_pred, labels=labels,\n",
        "                                    multi_class=\"ovr\", average=None)\n",
        "    return sum(weights * classes_roc_auc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "67791ff1",
      "metadata": {},
      "outputs": [],
      "source": [
        "cluster_weights = pd.read_excel(\"cluster_weights.xlsx\").set_index(\"cluster\")\n",
        "weights_dict = cluster_weights[\"unnorm_weight\"].to_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "b6ea63c8",
      "metadata": {},
      "outputs": [],
      "source": [
        "weits = [0]*17\n",
        "\n",
        "for k, v in category_mapping.items():\n",
        "    weits[category_mapping[k]] = weights_dict[k]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "ec1aaf24",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[3, 1, 3, 3, 3, 1, 1, 3, 2, 2, 1, 3, 2, 1, 3, 2, 2]"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weits"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91feaa10",
      "metadata": {},
      "source": [
        "треним"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "96ba5e21",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>balance_amt_avg</th>\n",
              "      <th>balance_amt_max</th>\n",
              "      <th>balance_amt_min</th>\n",
              "      <th>channel_code</th>\n",
              "      <th>city_type</th>\n",
              "      <th>ogrn_days_end_month</th>\n",
              "      <th>ogrn_days_end_quarter</th>\n",
              "      <th>ft_registration_date</th>\n",
              "      <th>max_founderpres</th>\n",
              "      <th>...</th>\n",
              "      <th>sum_deb_h_oper_1m_second</th>\n",
              "      <th>sum_cred_h_oper_1m_second</th>\n",
              "      <th>sum_deb_f_oper_3m_second</th>\n",
              "      <th>sum_cred_f_oper_3m_second</th>\n",
              "      <th>sum_cred_h_oper_3m_second</th>\n",
              "      <th>seg_segment_0</th>\n",
              "      <th>seg_segment_1</th>\n",
              "      <th>seg_segment_2</th>\n",
              "      <th>seg_segment_3</th>\n",
              "      <th>lasting</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0.692653</td>\n",
              "      <td>0.740253</td>\n",
              "      <td>0.430042</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.488553</td>\n",
              "      <td>-0.135063</td>\n",
              "      <td>2.485936</td>\n",
              "      <td>2.773674</td>\n",
              "      <td>...</td>\n",
              "      <td>0.419979</td>\n",
              "      <td>0.410410</td>\n",
              "      <td>-0.142187</td>\n",
              "      <td>-0.025646</td>\n",
              "      <td>0.990157</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.090605</td>\n",
              "      <td>-0.114275</td>\n",
              "      <td>-0.114119</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0.324343</td>\n",
              "      <td>1.258747</td>\n",
              "      <td>0.207790</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018270</td>\n",
              "      <td>-0.130732</td>\n",
              "      <td>-0.194911</td>\n",
              "      <td>-0.025646</td>\n",
              "      <td>-0.183854</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2</td>\n",
              "      <td>-0.148737</td>\n",
              "      <td>-0.187003</td>\n",
              "      <td>-0.112416</td>\n",
              "      <td>4</td>\n",
              "      <td>2281</td>\n",
              "      <td>-0.256297</td>\n",
              "      <td>-1.257854</td>\n",
              "      <td>0.327933</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.158938</td>\n",
              "      <td>-0.157599</td>\n",
              "      <td>-0.078440</td>\n",
              "      <td>-0.025646</td>\n",
              "      <td>-0.177854</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>3</td>\n",
              "      <td>-0.156522</td>\n",
              "      <td>-0.204718</td>\n",
              "      <td>-0.125759</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.185321</td>\n",
              "      <td>-0.367365</td>\n",
              "      <td>-0.391211</td>\n",
              "      <td>-0.398217</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.158938</td>\n",
              "      <td>-0.171825</td>\n",
              "      <td>-0.213518</td>\n",
              "      <td>-0.025646</td>\n",
              "      <td>-0.201123</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>4</td>\n",
              "      <td>-0.141798</td>\n",
              "      <td>-0.170262</td>\n",
              "      <td>-0.125672</td>\n",
              "      <td>43</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.417577</td>\n",
              "      <td>-0.444799</td>\n",
              "      <td>0.443499</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.090031</td>\n",
              "      <td>-0.151850</td>\n",
              "      <td>-0.213518</td>\n",
              "      <td>-0.025646</td>\n",
              "      <td>-0.176923</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>599987</th>\n",
              "      <td>199995</td>\n",
              "      <td>-0.039281</td>\n",
              "      <td>-0.053694</td>\n",
              "      <td>-0.044193</td>\n",
              "      <td>44</td>\n",
              "      <td>0</td>\n",
              "      <td>1.601751</td>\n",
              "      <td>-0.638383</td>\n",
              "      <td>-0.395216</td>\n",
              "      <td>-0.402632</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.079516</td>\n",
              "      <td>-0.171825</td>\n",
              "      <td>-0.213518</td>\n",
              "      <td>-0.025646</td>\n",
              "      <td>-0.201123</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>599990</th>\n",
              "      <td>199996</td>\n",
              "      <td>0.293117</td>\n",
              "      <td>0.189316</td>\n",
              "      <td>0.857952</td>\n",
              "      <td>6</td>\n",
              "      <td>1968</td>\n",
              "      <td>-0.953065</td>\n",
              "      <td>-0.328648</td>\n",
              "      <td>1.177518</td>\n",
              "      <td>1.331217</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.149905</td>\n",
              "      <td>-0.171825</td>\n",
              "      <td>-0.213216</td>\n",
              "      <td>-0.025646</td>\n",
              "      <td>-0.201123</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>599993</th>\n",
              "      <td>199997</td>\n",
              "      <td>0.032941</td>\n",
              "      <td>0.140726</td>\n",
              "      <td>-0.125362</td>\n",
              "      <td>43</td>\n",
              "      <td>0</td>\n",
              "      <td>1.485623</td>\n",
              "      <td>-0.677100</td>\n",
              "      <td>-0.395788</td>\n",
              "      <td>-0.403263</td>\n",
              "      <td>...</td>\n",
              "      <td>0.064755</td>\n",
              "      <td>0.125156</td>\n",
              "      <td>-0.164626</td>\n",
              "      <td>-0.025646</td>\n",
              "      <td>0.496713</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>599996</th>\n",
              "      <td>199998</td>\n",
              "      <td>-0.156776</td>\n",
              "      <td>-0.204960</td>\n",
              "      <td>-0.125995</td>\n",
              "      <td>44</td>\n",
              "      <td>0</td>\n",
              "      <td>0.324343</td>\n",
              "      <td>-1.064270</td>\n",
              "      <td>-0.348875</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.158938</td>\n",
              "      <td>-0.171825</td>\n",
              "      <td>-0.213518</td>\n",
              "      <td>-0.025646</td>\n",
              "      <td>-0.201123</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>599999</th>\n",
              "      <td>199999</td>\n",
              "      <td>-0.156712</td>\n",
              "      <td>-0.204913</td>\n",
              "      <td>-0.125831</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1.717879</td>\n",
              "      <td>1.762067</td>\n",
              "      <td>1.520785</td>\n",
              "      <td>0.716896</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.158938</td>\n",
              "      <td>-0.171825</td>\n",
              "      <td>-0.213518</td>\n",
              "      <td>-0.025646</td>\n",
              "      <td>-0.201123</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>206</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200000 rows × 119 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            id  balance_amt_avg  balance_amt_max  balance_amt_min  \\\n",
              "2            0         0.692653         0.740253         0.430042   \n",
              "5            1        -0.090605        -0.114275        -0.114119   \n",
              "8            2        -0.148737        -0.187003        -0.112416   \n",
              "11           3        -0.156522        -0.204718        -0.125759   \n",
              "14           4        -0.141798        -0.170262        -0.125672   \n",
              "...        ...              ...              ...              ...   \n",
              "599987  199995        -0.039281        -0.053694        -0.044193   \n",
              "599990  199996         0.293117         0.189316         0.857952   \n",
              "599993  199997         0.032941         0.140726        -0.125362   \n",
              "599996  199998        -0.156776        -0.204960        -0.125995   \n",
              "599999  199999        -0.156712        -0.204913        -0.125831   \n",
              "\n",
              "        channel_code  city_type  ogrn_days_end_month  ogrn_days_end_quarter  \\\n",
              "2                 40          0            -0.488553              -0.135063   \n",
              "5                 12          0             0.324343               1.258747   \n",
              "8                  4       2281            -0.256297              -1.257854   \n",
              "11                 6          0            -1.185321              -0.367365   \n",
              "14                43          0            -1.417577              -0.444799   \n",
              "...              ...        ...                  ...                    ...   \n",
              "599987            44          0             1.601751              -0.638383   \n",
              "599990             6       1968            -0.953065              -0.328648   \n",
              "599993            43          0             1.485623              -0.677100   \n",
              "599996            44          0             0.324343              -1.064270   \n",
              "599999             6          0             1.717879               1.762067   \n",
              "\n",
              "        ft_registration_date  max_founderpres  ...  sum_deb_h_oper_1m_second  \\\n",
              "2                   2.485936         2.773674  ...                  0.419979   \n",
              "5                   0.207790        -1.000000  ...                 -0.018270   \n",
              "8                   0.327933        -1.000000  ...                 -0.158938   \n",
              "11                 -0.391211        -0.398217  ...                 -0.158938   \n",
              "14                  0.443499        -1.000000  ...                 -0.090031   \n",
              "...                      ...              ...  ...                       ...   \n",
              "599987             -0.395216        -0.402632  ...                 -0.079516   \n",
              "599990              1.177518         1.331217  ...                 -0.149905   \n",
              "599993             -0.395788        -0.403263  ...                  0.064755   \n",
              "599996             -0.348875        -1.000000  ...                 -0.158938   \n",
              "599999              1.520785         0.716896  ...                 -0.158938   \n",
              "\n",
              "        sum_cred_h_oper_1m_second  sum_deb_f_oper_3m_second  \\\n",
              "2                        0.410410                 -0.142187   \n",
              "5                       -0.130732                 -0.194911   \n",
              "8                       -0.157599                 -0.078440   \n",
              "11                      -0.171825                 -0.213518   \n",
              "14                      -0.151850                 -0.213518   \n",
              "...                           ...                       ...   \n",
              "599987                  -0.171825                 -0.213518   \n",
              "599990                  -0.171825                 -0.213216   \n",
              "599993                   0.125156                 -0.164626   \n",
              "599996                  -0.171825                 -0.213518   \n",
              "599999                  -0.171825                 -0.213518   \n",
              "\n",
              "        sum_cred_f_oper_3m_second  sum_cred_h_oper_3m_second  seg_segment_0  \\\n",
              "2                       -0.025646                   0.990157              0   \n",
              "5                       -0.025646                  -0.183854              0   \n",
              "8                       -0.025646                  -0.177854              0   \n",
              "11                      -0.025646                  -0.201123              0   \n",
              "14                      -0.025646                  -0.176923              0   \n",
              "...                           ...                        ...            ...   \n",
              "599987                  -0.025646                  -0.201123              0   \n",
              "599990                  -0.025646                  -0.201123              0   \n",
              "599993                  -0.025646                   0.496713              1   \n",
              "599996                  -0.025646                  -0.201123              0   \n",
              "599999                  -0.025646                  -0.201123              0   \n",
              "\n",
              "        seg_segment_1  seg_segment_2  seg_segment_3  lasting  \n",
              "2                   1              0              0       12  \n",
              "5                   1              0              0      185  \n",
              "8                   0              0              1      237  \n",
              "11                  0              0              1      124  \n",
              "14                  0              1              0      244  \n",
              "...               ...            ...            ...      ...  \n",
              "599987              0              1              0      123  \n",
              "599990              1              0              0       83  \n",
              "599993              0              0              0      123  \n",
              "599996              0              0              1      126  \n",
              "599999              0              0              1      206  \n",
              "\n",
              "[200000 rows x 119 columns]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "ca21d155",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2          0\n",
              "5          0\n",
              "8         15\n",
              "11         3\n",
              "14        15\n",
              "          ..\n",
              "599987     0\n",
              "599990     3\n",
              "599993     0\n",
              "599996     1\n",
              "599999     1\n",
              "Name: end_cluster, Length: 200000, dtype: int32"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "a81d6e35",
      "metadata": {},
      "outputs": [],
      "source": [
        "y = df['end_cluster']\n",
        "X = df.drop(['end_cluster'], axis=1)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "c47ced68",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Init...\n",
            "Init Finished!\n"
          ]
        }
      ],
      "source": [
        "boosting = Boosting(X_train, X_val, y_train, y_val, cat_features = [])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "9e95a724",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Learning rate set to 0.221534\n",
            "0:\ttest: 0.8191063\tbest: 0.8191063 (0)\ttotal: 3.65s\tremaining: 12m 7s\n",
            "100:\ttest: 0.9358974\tbest: 0.9358974 (100)\ttotal: 8m 2s\tremaining: 7m 53s\n",
            "199:\ttest: 0.9364081\tbest: 0.9385534 (161)\ttotal: 17m 3s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.9385533638\n",
            "bestIteration = 161\n",
            "\n",
            "Shrink model to first 162 iterations.\n"
          ]
        }
      ],
      "source": [
        "boosting.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aeda601a",
      "metadata": {},
      "source": [
        "сохраняем загружаем"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "bf52d538",
      "metadata": {},
      "outputs": [],
      "source": [
        "boosting.save_model('model4_new_coding_nocorr.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "533e53f7",
      "metadata": {},
      "outputs": [],
      "source": [
        "boosting.load_model('model4_new_coding_nocorr.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7e0150e",
      "metadata": {},
      "source": [
        "получаем ответ на тесте"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "1b28c8c2",
      "metadata": {},
      "outputs": [
        {
          "ename": "CatBoostError",
          "evalue": "C:/Go_Agent/pipelines/BuildMaster/catboost.git/catboost/libs/data/model_dataset_compatibility.cpp:81: At position 4 should be feature with name balance_amt_day_avg (found channel_code).",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ans \u001b[38;5;241m=\u001b[39m \u001b[43mboosting\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Anaconda\\lib\\site-packages\\catboost\\core.py:5187\u001b[0m, in \u001b[0;36mCatBoostClassifier.predict\u001b[1;34m(self, data, prediction_type, ntree_start, ntree_end, thread_count, verbose, task_type)\u001b[0m\n\u001b[0;32m   5136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, prediction_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClass\u001b[39m\u001b[38;5;124m'\u001b[39m, ntree_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, ntree_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, thread_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, task_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCPU\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   5137\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5138\u001b[0m \u001b[38;5;124;03m    Predict with data.\u001b[39;00m\n\u001b[0;32m   5139\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5185\u001b[0m \u001b[38;5;124;03m              with log probability for every class for each object.\u001b[39;00m\n\u001b[0;32m   5186\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mntree_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mntree_end\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthread_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpredict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_type\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Anaconda\\lib\\site-packages\\catboost\\core.py:2546\u001b[0m, in \u001b[0;36mCatBoost._predict\u001b[1;34m(self, data, prediction_type, ntree_start, ntree_end, thread_count, verbose, parent_method_name, task_type)\u001b[0m\n\u001b[0;32m   2543\u001b[0m data, data_is_single_object \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_predict_input_data(data, parent_method_name, thread_count)\n\u001b[0;32m   2544\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_prediction_type(prediction_type)\n\u001b[1;32m-> 2546\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_base_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mntree_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mntree_end\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthread_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2547\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictions[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m data_is_single_object \u001b[38;5;28;01melse\u001b[39;00m predictions\n",
            "File \u001b[1;32md:\\Anaconda\\lib\\site-packages\\catboost\\core.py:1813\u001b[0m, in \u001b[0;36m_CatBoostBase._base_predict\u001b[1;34m(self, pool, prediction_type, ntree_start, ntree_end, thread_count, verbose, task_type)\u001b[0m\n\u001b[0;32m   1812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_base_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, pool, prediction_type, ntree_start, ntree_end, thread_count, verbose, task_type):\n\u001b[1;32m-> 1813\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_base_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mntree_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mntree_end\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthread_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_type\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m_catboost.pyx:4760\u001b[0m, in \u001b[0;36m_catboost._CatBoost._base_predict\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32m_catboost.pyx:4767\u001b[0m, in \u001b[0;36m_catboost._CatBoost._base_predict\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mCatBoostError\u001b[0m: C:/Go_Agent/pipelines/BuildMaster/catboost.git/catboost/libs/data/model_dataset_compatibility.cpp:81: At position 4 should be feature with name balance_amt_day_avg (found channel_code)."
          ]
        }
      ],
      "source": [
        "ans = boosting.model.predict(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "66d8f2b4",
      "metadata": {},
      "outputs": [],
      "source": [
        "data = {} #{'id': test.id.to_list()}\n",
        "for cls, prob in zip(category_mapping.keys(), ans):\n",
        "    data[cls] = prob\n",
        "\n",
        "column_mapping = {\n",
        "    0: '{other}',\n",
        "    1: '{}',\n",
        "    2: '{α, β}',\n",
        "    3: '{α, γ}',\n",
        "    4: '{α, δ}',\n",
        "    5: '{α, ε, η}',\n",
        "    6: '{α, ε, θ}',\n",
        "    7: '{α, ε, ψ}',\n",
        "    8: '{α, ε}',\n",
        "    9: '{α, η}',\n",
        "    10: '{α, θ}',\n",
        "    11: '{α, λ}',\n",
        "    12: '{α, μ}',\n",
        "    13: '{α, π}',\n",
        "    14: '{α, ψ}',\n",
        "    15: '{α}',\n",
        "    16: '{λ}'\n",
        "}\n",
        "\n",
        "output = pd.DataFrame(ans)\n",
        "output = output.rename(columns=column_mapping)\n",
        "output = output.assign(id=test['id'].tolist())\n",
        "\n",
        "sample_submission_df = pd.read_csv(\"sample_submission.csv\")\n",
        "output[list(sample_submission_df.columns)].to_csv('ans6.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d61ae3af",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['id',\n",
              " '{other}',\n",
              " '{}',\n",
              " '{α, β}',\n",
              " '{α, γ}',\n",
              " '{α, δ}',\n",
              " '{α, ε, η}',\n",
              " '{α, ε, θ}',\n",
              " '{α, ε, ψ}',\n",
              " '{α, ε}',\n",
              " '{α, η}',\n",
              " '{α, θ}',\n",
              " '{α, λ}',\n",
              " '{α, μ}',\n",
              " '{α, π}',\n",
              " '{α, ψ}',\n",
              " '{α}',\n",
              " '{λ}']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "sample_submission_df = pd.read_csv(\"sample_submission.csv\")\n",
        "list(sample_submission_df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1a205b27",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "e4ead55ff0a49c8ee3cc879f2470f4d9\n"
          ]
        }
      ],
      "source": [
        "import hashlib\n",
        "\n",
        "def generate_md5(file_path):\n",
        "    # Open the file in binary mode\n",
        "    with open(file_path, \"rb\") as file:\n",
        "        # Read the content of the file\n",
        "        content = file.read()\n",
        "        # Generate the MD5 hash of the content\n",
        "        md5_hash = hashlib.md5(content).hexdigest()\n",
        "        return md5_hash\n",
        "\n",
        "# Call the function to generate the MD5 hash of a video file\n",
        "# Replace \"video.mp4\" with the path to your video file\n",
        "md5_hash = generate_md5(r\"C:\\Users\\alina\\Videos\\2024-03-12 14-31-10.mkv\")\n",
        "\n",
        "# Print the MD5 hash\n",
        "print(md5_hash)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3221f313",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "python3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
